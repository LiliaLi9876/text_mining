{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LAB 3. TEXT CLASSIFICATION** \n",
    "\n",
    "### **<font color=green>INSTRUCTIONS:</font>** <br> \n",
    "\n",
    "**<font color=green> 1. Look for EXERCISES in the script.</font>** <br>\n",
    "\n",
    "**<font color=green> 2. Each student INDIVIDUALLY uploads this script with their answers embedded to Canvas by the end of the lab session (recommended) or by Wednesday, 11:59pm Central Time.</font>** \n",
    "\n",
    "<font color=green>**Note:** Jupyter cloud can be found here if you need it: [jupyter.org/try](jupyter.org/try). You are likely to need it if you attend remotely from China (to access the web-based dataset we use in the lab). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Objective\n",
    "Our objective is to classify consumer messages based on the topic of the message. Today, you will:<br>\n",
    "1. Learn how to vectorize *training* data and *testing* data (**watch out for very important nuances in the script!**)\n",
    "2. Do feature selection using **filter** methods: chi-squared statistics and a variation on the entropy statistic called mutual information.\n",
    "3. Train and test a **Naive Bayes classifier** for text data (you can use other methods, such as Support Vector Machines).\n",
    "\n",
    "\n",
    "### Session Prep\n",
    "Install the modules we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (1.20.1)\n",
      "Requirement already satisfied: sklearn in /opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#instruct to not show the deprication warnings about future changes in the modules\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "!{sys.executable} -m pip install sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "!{sys.executable} -m pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text normalization function from Text_Normalization_Function.ipynb we used in Lab 2 (Important: Make sure Text_Normalization_Function.ipynb file is in the same directory as the current notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html.parser in /opt/anaconda3/lib/python3.8/site-packages (0.2)\n",
      "Requirement already satisfied: ply in /opt/anaconda3/lib/python3.8/site-packages (from html.parser) (3.11)\n",
      "Requirement already satisfied: pattern3 in /opt/anaconda3/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: pdfminer3k in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (1.3.4)\n",
      "Requirement already satisfied: cherrypy in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (18.6.1)\n",
      "Requirement already satisfied: docx in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: feedparser in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (6.0.8)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (4.9.3)\n",
      "Requirement already satisfied: pdfminer.six in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (20211012)\n",
      "Requirement already satisfied: simplejson in /opt/anaconda3/lib/python3.8/site-packages (from pattern3) (3.17.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->pattern3) (2.2.1)\n",
      "Requirement already satisfied: portend>=2.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.8/site-packages (from cherrypy->pattern3) (8.7.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from cherrypy->pattern3) (8.5.2)\n",
      "Requirement already satisfied: jaraco.collections in /opt/anaconda3/lib/python3.8/site-packages (from cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: zc.lockfile in /opt/anaconda3/lib/python3.8/site-packages (from cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/anaconda3/lib/python3.8/site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (1.15.0)\n",
      "Requirement already satisfied: tempora>=1.8 in /opt/anaconda3/lib/python3.8/site-packages (from portend>=2.1.1->cherrypy->pattern3) (4.1.2)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.8/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2021.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from docx->pattern3) (8.2.0)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.8/site-packages (from docx->pattern3) (4.6.3)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/lib/python3.8/site-packages (from feedparser->pattern3) (1.0.0)\n",
      "Requirement already satisfied: jaraco.text in /opt/anaconda3/lib/python3.8/site-packages (from jaraco.collections->cherrypy->pattern3) (3.6.0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/anaconda3/lib/python3.8/site-packages (from jaraco.collections->cherrypy->pattern3) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/lib/python3.8/site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern3) (3.4.1)\n",
      "Requirement already satisfied: cryptography in /opt/anaconda3/lib/python3.8/site-packages (from pdfminer.six->pattern3) (3.4.7)\n",
      "Requirement already satisfied: chardet in /opt/anaconda3/lib/python3.8/site-packages (from pdfminer.six->pattern3) (4.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.8/site-packages (from cryptography->pdfminer.six->pattern3) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern3) (2.20)\n",
      "Requirement already satisfied: ply in /opt/anaconda3/lib/python3.8/site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from zc.lockfile->cherrypy->pattern3) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyLDAvis in /opt/anaconda3/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.24.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (52.0.0.post20210125)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: sklearn in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.20.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.2.4)\n",
      "Requirement already satisfied: funcy in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.16)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: numexpr in /opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.2.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->pyLDAvis) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lilia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb #defining text normalization function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Exploring Data\n",
    "\n",
    "**Important if you are attending remotely from China: To access the data from a website below, you might need to use VPN (might be slow) or Jupyter cloud at [jupyter.org/try](jupyter.org/try).**<br>\n",
    "\n",
    "Download the dataset from the dataset sklearn's collection of datasets (sklearn.datasets). The dataset we need is called fetch_20newsgroups:<br>\n",
    "\n",
    "You can check out the documentation for the dataset here: https://bit.ly/3aM5tUo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 20 newsgroups (topics) available, we will use posts on **4** topics: <br><br>-atheism<br> -religion<br> -computer graphics<br>-science<br><br> You can refer to those newsgroups as **classes** or **categories**. Note right away that the \"atheism\" and \"religion\" classes are likely **similar** to each other: people might be using similar words when they talk about atheism and religion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our **training** and **testing** datasets. We do that by picking the posts belonging to the selected classes, marked in the dataset \"test\" or \"train\". We remove headers (likely, email or letter headers), footers (containing author's signatures, etc.), and quotes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "corpus_train = fetch_20newsgroups(categories = categories,\n",
    "                                  subset = 'train', \n",
    "                                  remove = ('headers', 'footers', 'quotes')) \n",
    "\n",
    "corpus_test = fetch_20newsgroups(categories = categories,\n",
    "                                 subset='test', \n",
    "                                 remove=('headers', 'footers', 'quotes')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data by looking at the training text corpus. First, have a look at one of the posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acorn Replay running on a 25MHz ARM 3 processor (the ARM 3 is about 20% slower\n",
      "than the ARM 6) does this in software (off a standard CD-ROM). 16 bit colour at\n",
      "about the same resolution (so what if the computer only has 8 bit colour\n",
      "support, real-time dithering too...). The 3D0/O is supposed to have a couple of\n",
      "DSPs - the ARM being used for housekeeping.\n",
      "\n",
      "\n",
      "A 25MHz ARM 6xx should clock around 20 ARM MIPS, say 18 flat out. Depends\n",
      "really on the surrounding system and whether you are talking ARM6x or ARM6xx\n",
      "(the latter has a cache, and so is essential to run at this kind of speed with\n",
      "slower memory).\n",
      "\n",
      "I'll stop saying things there 'cos I'll hopefully be working for ARM after\n",
      "graduation...\n",
      "\n",
      "Mike\n",
      "\n",
      "PS Don't pay heed to what reps from Philips say; if the 3D0/O doesn't beat the\n",
      "   pants off 3DI then I'll eat this postscript.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(corpus_train.data[7])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels for each message that you will be using for training and testing are encoded as numbers and can be accessed via attribute **.target** and their names can be accessed via attribute **.target_names**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category names:  ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "Categories for first 10 observations:  [1 3 2 0 2 0 2 1 2 1]\n",
      "Number of posts in the training dataset:  2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(\"Category names: \", corpus_train.target_names)    \n",
    "print(\"Categories for first 10 observations: \", corpus_train.target[:10])     \n",
    "print(\"Number of posts in the training dataset: \", corpus_train.filenames.shape[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a function and call it **fmat_descr_fun** to be used later to describe the feature matrix (vectorized corpus). The function prints out the dimensions of the matrix, share of non-zero elements in the matrix and so on. The function takes two inputs: the feature matrix and your vectorizer function. <br><br>In what follows later, you will see the descriptives that the function produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def fmat_descr_fun(your_feature_matrix,your_vectorizer):\n",
    "    print(\"Dimensions (number of posts, number of features): \", your_feature_matrix.shape)  \n",
    "    print(\"The first 5 features - names: \", your_vectorizer.get_feature_names()[0:5]) \n",
    "    print(\"Share of non-zero elements in the matrix: \", \n",
    "          your_feature_matrix.nnz / (float(your_feature_matrix.shape[0]) * float(your_feature_matrix.shape[1])))\n",
    "    print(\"Average number of features present, per post: \", \n",
    "          round(your_feature_matrix.nnz/float(your_feature_matrix.shape[0]),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction for TRAINING Data\n",
    "\n",
    "Let's do feature extraction for our **TRAINING** data using the **\"Bag-of-words\"** method and **TF-IDF** method (optional).\n",
    "\n",
    "#### \"Bag-of-words\" Vectorization for TRAINING data\n",
    "\n",
    "As you remember from Lab 2, to do the Bag-of-Words vectorization, we can use the CountVectorizer function from the sklearn package: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our Bag-of-Words vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the vectorizer we defined, bow_vectorizer, to our training dataset, **without normalizing** it first (though tokenization will be done by the vectorizer). Remember, to create the corpus vocabulary and to vectorize the data accroding to that vocabulary, we use the **.fit_transform** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "corpus_train_bow = bow_vectorizer.fit_transform(corpus_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the Bag-of-Words matrix that you got by applying the function **fmat_descr_fun** we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions (number of posts, number of features):  (2034, 26879)\n",
      "The first 5 features - names:  ['00', '000', '0000', '00000', '000000']\n",
      "Share of non-zero elements in the matrix:  0.0035978272269590263\n",
      "Average number of features present, per post:  96.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "fmat_descr_fun(corpus_train_bow, bow_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first 5 rows in the resulting matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000005102000</th>\n",
       "      <th>000062david42</th>\n",
       "      <th>0001</th>\n",
       "      <th>000100255pixel</th>\n",
       "      <th>00041032</th>\n",
       "      <th>...</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurvanism</th>\n",
       "      <th>zus</th>\n",
       "      <th>zvi</th>\n",
       "      <th>zwaartepunten</th>\n",
       "      <th>zwak</th>\n",
       "      <th>zwakke</th>\n",
       "      <th>zware</th>\n",
       "      <th>zwarte</th>\n",
       "      <th>zyxel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000  000000  000005102000  000062david42  0001  \\\n",
       "0   0    0     0      0       0             0              0     0   \n",
       "1   0    0     0      0       0             0              0     0   \n",
       "2   0    0     0      0       0             0              0     0   \n",
       "3   0    0     0      0       0             0              0     0   \n",
       "4   0    0     0      0       0             0              0     0   \n",
       "\n",
       "   000100255pixel  00041032  ...  zurich  zurvanism  zus  zvi  zwaartepunten  \\\n",
       "0               0         0  ...       0          0    0    0              0   \n",
       "1               0         0  ...       0          0    0    0              0   \n",
       "2               0         0  ...       0          0    0    0              0   \n",
       "3               0         0  ...       0          0    0    0              0   \n",
       "4               0         0  ...       0          0    0    0              0   \n",
       "\n",
       "   zwak  zwakke  zware  zwarte  zyxel  \n",
       "0     0       0      0       0      0  \n",
       "1     0       0      0       0      0  \n",
       "2     0       0      0       0      0  \n",
       "3     0       0      0       0      0  \n",
       "4     0       0      0       0      0  \n",
       "\n",
       "[5 rows x 26879 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert vectorized data to a dataframe and give columns their names\n",
    "corpus_train_bow_table = pd.DataFrame(data = corpus_train_bow.todense(), columns = bow_vectorizer.get_feature_names())\n",
    "corpus_train_bow_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=green>EXERCISE 1:</font>**\n",
    "**<font color=green> Answer the following questions using the descriptives of the Bag-of-Words matrix:</font>** <br><br>\n",
    "**<font color=green>1.1. How many features does the Bag-of-Words matrix contain?</font>** <br><br> \n",
    "Your answer: 26879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>1.2. Is the Bag-of-Words matrix sparse? Explain your answer: </font>** <br><br> \n",
    "Your answer: Yes. Many of the words have frequency 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Many of the words have frequency 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize our training data and call the normalized corpus **NORM_corpus_train**. Note that it will take some time for the normalization function to finish its job as you are working with large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NORM_corpus_train = normalize_corpus(corpus_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=green>EXERCISE 2:</font>**\n",
    "**<font color=green>First, vectorize the normalized training corpus (NORM_corpus_train) using the Bag-of-Words approach and name the vectorized corpus NORM_corpus_train_bow.** <br><br>\n",
    "Your code:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NORM_corpus_train_bow = bow_vectorizer.fit_transform(NORM_corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>\n",
    "Second, describe the normalized training corpus using the fmat_descr_fun function.** <br><br> Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions (number of posts, number of features):  (2034, 21061)\n",
      "The first 5 features - names:  ['000062david42', '000100255pixel', '000usd', '001200201pixel', '00index']\n",
      "Share of non-zero elements in the matrix:  0.002958676433492318\n",
      "Average number of features present, per post:  62.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "fmat_descr_fun(NORM_corpus_train_bow, bow_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>2.1. What differences do you see between normalized and non-normalized feature matrices?</font>** <br><br>\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features decreses to 21061 from 26897. And the share of non-zero elements drops by anout 0.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection for TRAINING Data\n",
    "Let's select the best features for your normalized training corpus, **NORM_corpus_train_bow**, using the **chi-squared statistic** and **mutial information (MI)**, whcih is based on the ideas of **entropy**.<br><br>**IMPORTANT!** You need to be done with the previous EXERCISE to be able to continue. <br><br>We need to import the feature selection function **SelectKBest** first. This function selects k best features based on the results of a test (in our case, we will use chi-squared and mutual information). Also, we need the **chi2** function and **mutual_info_classif** functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to specify that we will use SelectKBest function with the chi-squared statistic for feature selection (by setting parameter \"score_func\") and indicate the number of best features we want to find (by setting parameter \"k\"). We'll select 10,000 best features, so **k = 10,000**:<br><br>\n",
    "*Look up the documentation for SelectKBest if needed: https://bit.ly/2Re54Ch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "chi2_kbest = SelectKBest(score_func = chi2, k = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the best features. To do that, we call the **fit_transform** method with our defined kbest function. The fit_transform method takes **2 inputs**: the vectorized representation of the data (NORM_corpus_train_bow) and the array of class labels contained in the object corpus_train.target. To see the chi-squared scores for the features use method **scores_**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.43001686, 2.48287671, 4.96575342, ..., 2.43001686, 4.86003373,\n",
       "       4.96575342])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORM_corpus_train_bow_chi2_BEST = chi2_kbest.fit_transform(NORM_corpus_train_bow, corpus_train.target)\n",
    "chi2_kbest.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which features are best? The **get_support** method with parameter *indices* set to True will return the indecies of the best k features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    2,     5,     7, ..., 21052, 21059, 21060])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_best_features_ind = chi2_kbest.get_support(indices=True)\n",
    "chi2_best_features_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the names of the best features, according to the chi-squared statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "chi2_best_features_names = np.array(bow_vectorizer.get_feature_names())[chi2_best_features_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data vectorized using best features selected based on the chi-squared statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000usd</th>\n",
       "      <th>00pm</th>\n",
       "      <th>023b</th>\n",
       "      <th>0x</th>\n",
       "      <th>1024x768</th>\n",
       "      <th>10bps</th>\n",
       "      <th>10km</th>\n",
       "      <th>10m</th>\n",
       "      <th>110m</th>\n",
       "      <th>115m</th>\n",
       "      <th>...</th>\n",
       "      <th>zoroaster</th>\n",
       "      <th>zoroastrian</th>\n",
       "      <th>zoroastrianism</th>\n",
       "      <th>zoroastrians</th>\n",
       "      <th>zubin</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zullen</th>\n",
       "      <th>zurvanism</th>\n",
       "      <th>zwarte</th>\n",
       "      <th>zyxel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000usd  00pm  023b  0x  1024x768  10bps  10km  10m  110m  115m  ...  \\\n",
       "0       0     0     0   0         0      0     0    0     0     0  ...   \n",
       "1       0     0     0   0         0      0     0    0     0     0  ...   \n",
       "2       0     0     0   0         0      0     0    0     0     0  ...   \n",
       "3       0     0     0   0         0      0     0    0     0     0  ...   \n",
       "4       0     0     0   0         0      0     0    0     0     0  ...   \n",
       "\n",
       "   zoroaster  zoroastrian  zoroastrianism  zoroastrians  zubin  zuck  zullen  \\\n",
       "0          0            0               0             0      0     0       0   \n",
       "1          0            0               0             0      0     0       0   \n",
       "2          0            0               0             0      0     0       0   \n",
       "3          0            0               0             0      0     0       0   \n",
       "4          0            0               0             0      0     0       0   \n",
       "\n",
       "   zurvanism  zwarte  zyxel  \n",
       "0          0       0      0  \n",
       "1          0       0      0  \n",
       "2          0       0      0  \n",
       "3          0       0      0  \n",
       "4          0       0      0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert vectorized data to a dataframe and give columns their names\n",
    "X_train_bow_chi2_BEST_table = pd.DataFrame(data = NORM_corpus_train_bow_chi2_BEST.todense(), columns = chi2_best_features_names)\n",
    "X_train_bow_chi2_BEST_table.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=green>EXERCISE 3:</font>**\n",
    "**<font color=green>3.1. Select best features using the mutual information statistic. Follow the steps we used for the chi-squared statistic. The first line, showing how to specify the SelectKBest function using mutual information, is provided. You need to complete the script.</font>** <br><br>\n",
    "*Note: you can check out the documentation for mutual information function for categorical data here: https://bit.ly/2JGgeeT* <br><br>\n",
    "Your code (add more lines):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8592"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_kbest = SelectKBest(score_func = mutual_info_classif, k = 10000)\n",
    "\n",
    "NORM_corpus_train_mutual_info_BEST = MI_kbest.fit_transform(NORM_corpus_train_bow, corpus_train.target)\n",
    "#MI_kbest.scores_\n",
    "mutual_info_best_features_ind = MI_kbest.get_support(indices=True)\n",
    "mutual_info_best_features_names = np.array(bow_vectorizer.get_feature_names())[mutual_info_best_features_ind]\n",
    "#sklearn.feature_selection.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)[source]\n",
    "X_train_mutual_info_BEST_table = pd.DataFrame(data = NORM_corpus_train_mutual_info_BEST.todense(), columns = mutual_info_best_features_names)\n",
    "X_train_mutual_info_BEST_table.head(5)\n",
    "\n",
    "mutual_info_best_features_ind_set = set(mutual_info_best_features_ind)\n",
    "chi2_best_features_ind_set = set(chi2_best_features_ind)\n",
    "len(chi2_best_features_ind_set.intersection(mutual_info_best_features_ind_set))/10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>3.2. Do mutual information approach and chi-squared statistic select the same best features?</font>** <br>\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "85.92% of the best index are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction for TEST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize and vectorize the **TEST** text corpus (corpus_test.data) using the Bag-of-Words method. <br><br>First, we normalize the testing corpus and call it NORM_corpus_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NORM_corpus_test = normalize_corpus(corpus_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize the normalized test corpus, NORM_corpus_test. <br><br>\n",
    "**IMPORTANT! For transforming test data, you'll use features extracted from the training corpus [You do NOT want to create new feature based on your test data].** <br><br>Therefore: <br> 1) do **not** define a new vectorizer, use the one used on training data <br>2) use method **.transform** (not .fit_trandform) with your vectorizer to vectorize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NORM_corpus_test_bow = bow_vectorizer.transform(NORM_corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the best features selected by **chi-squared statistic**. Now we need to pick up from the above Bag-of-Words matrix exactly the same best features we selected for our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORM_corpus_test_bow_chi2_BEST = chi2_kbest.transform(NORM_corpus_test_bow)\n",
    "type(NORM_corpus_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "\n",
    "We'll train a text classification model that categorizes documents into 4 classes: religion, atheism, science and computer graphics. We will use a Naive Bayes Classifier and Support Vector Machines (SVM), the last one is optional.\n",
    "\n",
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the **MultinomialNB** packages available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Naive Bayes classifier by specifiying the hyperparameter alpha and call the classifier NB_tc:<br><br>\n",
    "*Note: you can set the hyperparameter alpha to an optimal value by trying different values > 0. With alpha = 0, you model will assign a probability of zero to a document in the test data if the document contains a feature not found in the training data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NB_tc = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model using the best features selected using the **chi-squared statistics**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_tc.fit(NORM_corpus_train_bow_chi2_BEST, corpus_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "predicted_nb_chi2_best = NB_tc.predict(NORM_corpus_test_bow_chi2_BEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the predictive power for the Naive Bayes classifier using chi-squared k=10,000 best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "                     alt.atheism  comp.graphics  sci.space  talk.religion.misc\n",
      "alt.atheism                 231              7         25                  56\n",
      "comp.graphics                15            349         23                   2\n",
      "sci.space                    20             18        349                   7\n",
      "talk.religion.misc           77              5         19                 150 \n",
      "\n",
      "Accuracy rate:  0.7974870657797487 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cm_chi2_best = metrics.confusion_matrix(corpus_test.target, predicted_nb_chi2_best)\n",
    "print(\"Confusion matrix: \\n\", pd.DataFrame(data = cm_chi2_best , \n",
    "                                           columns = corpus_train.target_names,\n",
    "                                           index = corpus_train.target_names),\"\\n\")\n",
    "print(\"Accuracy rate: \", metrics.accuracy_score(corpus_test.target, predicted_nb_chi2_best),\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=green>EXERCISE 4:</font>**\n",
    "**<font color=green>4.1. Train the Naive Bayes classifier without doing feature selection, that is use all the features available in the normalized corpus. </font>** <br><br>\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NB_tc.fit(NORM_corpus_train_bow, corpus_train.target)\n",
    "\n",
    "predicted_nb_no_sele = NB_tc.predict(NORM_corpus_test_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "                     alt.atheism  comp.graphics  sci.space  talk.religion.misc\n",
      "alt.atheism                 227              6         24                  62\n",
      "comp.graphics                12            350         23                   4\n",
      "sci.space                    19             18        348                   9\n",
      "talk.religion.misc           79              8         18                 146 \n",
      "\n",
      "Accuracy rate:  0.7915742793791575 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cm_no_sele = metrics.confusion_matrix(corpus_test.target, predicted_nb_no_sele)\n",
    "print(\"Confusion matrix: \\n\", pd.DataFrame(data = cm_no_sele , \n",
    "                                           columns = corpus_train.target_names,\n",
    "                                           index = corpus_train.target_names),\"\\n\")\n",
    "print(\"Accuracy rate: \", metrics.accuracy_score(corpus_test.target, predicted_nb_no_sele),\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>What accuracy do you get? If a classifier did a mistake and misclassified a \"Computer Graphics\" post, to which class such a post was mistakenly assigned, typically? What about a post on the \"Atheism\" topic? </font>** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The accuracy is 79.16%.\n",
    "If a classifier did a mistake and misclassified a \"Computer Graphics\" post, most likely, it will be assigned to the\n",
    "class sci.sapce, and then alt.atheism, and at last, talk.religion.misc.\n",
    "For an alt.atheism topic, it will, most likely, be misclassified to talk.religion.misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=green>4.2. (OPTIONAL) Train the Naive Bayes classifier feature selection based on mutual information (MI). What accuracy do you get?**<br><br>\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "NORM_corpus_test_bow_mi_BEST = MI_kbest.transform(NORM_corpus_test_bow)\n",
    "\n",
    "NB_tc.fit(NORM_corpus_train_mutual_info_BEST, corpus_train.target)\n",
    "\n",
    "predicted_nb_mi = NB_tc.predict(NORM_corpus_test_bow_mi_BEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "                     alt.atheism  comp.graphics  sci.space  talk.religion.misc\n",
      "alt.atheism                 237              7         24                  51\n",
      "comp.graphics                10            351         24                   4\n",
      "sci.space                    20             18        349                   7\n",
      "talk.religion.misc           84              7         19                 141 \n",
      "\n",
      "Accuracy rate:  0.7967479674796748 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cm_no_mi = metrics.confusion_matrix(corpus_test.target, predicted_nb_mi)\n",
    "print(\"Confusion matrix: \\n\", pd.DataFrame(data = cm_no_mi , \n",
    "                                           columns = corpus_train.target_names,\n",
    "                                           index = corpus_train.target_names),\"\\n\")\n",
    "print(\"Accuracy rate: \", metrics.accuracy_score(corpus_test.target, predicted_nb_mi),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "The accuracy is 79.67%, higher than the two methods above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=green>EXERCISE 5 (OPTIONAL):</font>**\n",
    "**<font color=green>5.1. Vectorize the data using the TF-IDF approach, with and without feature selection, and train and test the Naive Bayes classifier. What are your results? </font>** <br><br>\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
